\section{Conclusion}
 As it was used so many times before, now it is time to conclude what controversial source data is in reality because there are so many different interpretations of the definition of what exactly controversial source data is, but after investigating this question and careful evaluation, I can outline 3 main groups, firstly the unreliable sources, which cannot be truthful due to the high number of mismatches with reality, such kind of controversy can be a huge problem for people who rely on LM in actions where the accuracy is really mandatory, thus people will never trust AI for 100 percent bc of the fear of being deceived. The second type of controversial source data is harmful language, which can be considered as the one that can destroy relations between people, ignite new hotbeds of disputes and debates, and also that the most terrible thing is the oppression of small groups, which shows people in those very groups how even a trained language model does not spread oppression, oppression and bullying of minorities and not only, it still shows its racist, sexist, homophobic side. And the last, but not less important third type – mismatch information, the information from different sources can differ in some details, it is not the same as unreliability because here there are no true or right answers, due to the variety of perspectives, it has occurred in the history that some people see some things really different from what see others. That's why something that is true for some groups can be false and reversed. \\
 
The influence of controversial aspects in almost every real-world dataset on LM performance is usually not so critical, but in particular, in cases when the output of LM can affect people’s lives, it should be reduced at that time, due to the high risk of occurring of new issues related to the society, or just get less depended to it. However, we have a variety of different approaches to mitigate this problem, but none of them can ensure the end user that the product can be 100 percent accurate and unbiased. Right now, I do not see a better solution than trying to minimize its influence on the performance of the Language model and the dependency of the Model to gain new views for expanding the possibilities of LM. In the future, it would be great if there would be researchers according to conceptual filtering which is in my opinion the best solution right now, but the problem of losing some viewpoints also does not let all people use it, and because of the high cost of the technique. 

 